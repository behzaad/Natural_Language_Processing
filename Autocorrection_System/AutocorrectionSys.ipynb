{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutocorrectionSys.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we implement an autocorrect system. "
      ],
      "metadata": {
        "id": "rvS-3_Gm1IHH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ckMaTtA-o8YE"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we read the data set and split it to a list of unique words. Also, we make sure all words are lower-case:"
      ],
      "metadata": {
        "id": "w66W1v4BtGMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = '/content/shakespeare.txt'\n",
        "with open(file_name) as f:\n",
        "  data = f.read()\n",
        "\n",
        "data = data.lower()\n",
        "words = re.findall('\\w+', data)"
      ],
      "metadata": {
        "id": "-bfui8HipODQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the mentioned pre-processes, we now calculate the frequency of each word in the given data set"
      ],
      "metadata": {
        "id": "6VNpIQJppyHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_count_dict = Counter(words)"
      ],
      "metadata": {
        "id": "zstVBiJbpqub"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we calculate the probability that each word will appear if randomly selected from the corpus of words"
      ],
      "metadata": {
        "id": "hXxH8bPHqHtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probs = {} # probs is a dictionary: key: word, value: probability\n",
        "\n",
        "M = sum( word_count_dict.values() ) # Total number of words in the given dataset\n",
        "\n",
        "for word in word_count_dict.keys():\n",
        "  probs[word] = word_count_dict[word]/M"
      ],
      "metadata": {
        "id": "DzAR7-bIpsEq"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **String Manipulations**\n",
        "\n",
        "We write several functions to manipulate strings so that we can edit the erroneous strings and return the right spellings of the words.\n",
        "\n",
        "We implement the following methods:\n",
        "\n",
        "* `delete_letter`: given a word, it returns all the possible strings that have **one character removed**. \n",
        "* `switch_letter`: given a word, it returns all the possible strings that have **two adjacent letters switched**.\n",
        "* `replace_letter`: given a word, it returns all the possible strings that have **one character replaced by another different letter**.\n",
        "* `insert_letter`: given a word, it returns all the possible strings that have an **additional character inserted**. "
      ],
      "metadata": {
        "id": "t5M7Y60-qqRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_letter(word):\n",
        "    '''\n",
        "    Input:\n",
        "        word: the string/word for which we will generate all possible words \n",
        "                in the vocabulary which have 1 missing character\n",
        "    Output:\n",
        "        delete_l: a list of all possible strings obtained by deleting 1 character from word\n",
        "    '''\n",
        "    split_l = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
        "    delete_l = [L + R[1:] for (L,R) in split_l if R]\n",
        "\n",
        "    return  delete_l\n",
        "\n",
        "\n",
        "def switch_letter(word):\n",
        "    '''\n",
        "    Input:\n",
        "        word: input string\n",
        "     Output:\n",
        "        switches: a list of all possible strings with one adjacent charater switched\n",
        "    ''' \n",
        "\n",
        "    split_l = [(word[:i], word[i:]) for i in range(len(word)+1)]\n",
        "    switch_l = [L + R[1] + R[0] + R[2:] for (L,R) in split_l if len(R) >=2]\n",
        "\n",
        "    return switch_l\n",
        "\n",
        "\n",
        "\n",
        "def replace_letter(word):\n",
        "    '''\n",
        "    Input:\n",
        "        word: the input string/word \n",
        "    Output:\n",
        "        replaces: a list of all possible strings where we replaced one letter from the original word. \n",
        "    ''' \n",
        "    \n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "\n",
        "    split_l = [(word[:i], word[i:]) for i in range(len(word)+1)]\n",
        "    replace_set = {L + letter + (R[1:] if len(R)>1 else '') for (L,R) in split_l if R for letter in letters }\n",
        "    replace_set.remove(word)\n",
        "\n",
        "    replace_l = sorted(list(replace_set)) \n",
        "    \n",
        "    return replace_l\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def insert_letter(word):\n",
        "    '''\n",
        "    Input:\n",
        "        word: the input string/word \n",
        "    Output:\n",
        "        inserts: a set of all possible strings with one new letter inserted at every offset\n",
        "    ''' \n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    \n",
        "    split_l = [(word[:i], word[i:]) for i in range(len(word)+1)]\n",
        "    insert_l = [L + letter + R for (L,R) in split_l for letter in letters]\n",
        "    \n",
        "    return insert_l"
      ],
      "metadata": {
        "id": "Q1V1wMxRqkQN"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following, we implement a function to get all the possible edits that are one edit away from the given word. The edits consist of the replace, insert, delete, and the switch operation. "
      ],
      "metadata": {
        "id": "wcqEBKqCuD92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_one_letter(word, allow_switches = True):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        word: the string/word for which we will generate all possible words that are one edit away.\n",
        "    Output:\n",
        "        edit_one_set: a set of words with one possible edit. output is a set, not a list!\n",
        "    \"\"\"\n",
        "    \n",
        "    edit_one_set = set()\n",
        "\n",
        "    edit_one_set.update(delete_letter(word))\n",
        "    if allow_switches:\n",
        "        edit_one_set.update(switch_letter(word))\n",
        "    edit_one_set.update(replace_letter(word))\n",
        "    edit_one_set.update(insert_letter(word))\n",
        "\n",
        "    return set(edit_one_set)\n",
        "\n"
      ],
      "metadata": {
        "id": "4yPAAEqqrnv-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can generalize this to implement to get two edits on a word:"
      ],
      "metadata": {
        "id": "yI_seeVguRxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_two_letters(word, allow_switches = True):\n",
        "    '''\n",
        "    Input:\n",
        "        word: the input string/word \n",
        "    Output:\n",
        "        edit_two_set: a set of strings with all possible two edits\n",
        "    '''\n",
        "    \n",
        "    edit_two_set = set()\n",
        "    \n",
        "    edit_one = edit_one_letter(word,allow_switches=allow_switches)\n",
        "    for w in edit_one:\n",
        "        if w:\n",
        "            edit_two = edit_one_letter(w,allow_switches=allow_switches)\n",
        "            edit_two_set.update(edit_two)\n",
        "    \n",
        "    return set(edit_two_set)"
      ],
      "metadata": {
        "id": "tykrwLxIrwGg"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_corrections(word, probs, vocab, n=2):\n",
        "    '''\n",
        "    Input: \n",
        "        word: a user entered string to check for suggestions\n",
        "        probs: a dictionary that maps each word to its probability in the corpus\n",
        "        vocab: a set containing all the vocabulary\n",
        "        n: number of possible word corrections we want returned in the dictionary\n",
        "    Output: \n",
        "        n_best: a list of tuples with the most probable n corrected words and their probabilities.\n",
        "    '''\n",
        "    \n",
        "    suggestions = []\n",
        "    n_best = []\n",
        "    \n",
        "    E1 = edit_one_letter(word)\n",
        "    E2 = edit_two_letters(word)\n",
        "    \n",
        "    if word in vocab:\n",
        "        suggestions.append(word)\n",
        "    \n",
        "    if not suggestions:\n",
        "        for w in E1: \n",
        "            if w in vocab:\n",
        "                suggestions.append(w)\n",
        "                \n",
        "    if not suggestions:\n",
        "        for w in E2:\n",
        "            if w in vocab:\n",
        "                suggestions.append(w)\n",
        "    \n",
        "                    \n",
        "    \n",
        "    sugg_probs = [(w,probs[w]) for w in suggestions]\n",
        "    sorted_sugg = sorted(sugg_probs, key = lambda x: x[1], reverse = True)\n",
        "    n_best = sorted_sugg[:n]\n",
        "    \n",
        "    \n",
        "    print(\"entered word = \", word, \"\\nsuggestions = \", suggestions)\n",
        "\n",
        "    return n_best"
      ],
      "metadata": {
        "id": "8FePsFsor3UT"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can test the performanc of our autocorrect system using misspelled words:"
      ],
      "metadata": {
        "id": "x2KnCDRZ054e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = words\n",
        "my_word = 'recieve' \n",
        "tmp_corrections = get_corrections(my_word, probs, vocab , 2)\n",
        "for i, word_prob in enumerate(tmp_corrections):\n",
        "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93R2hHu0sJBa",
        "outputId": "30c9ccd0-1269-48c9-a874-4e70e2a76bbe"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "entered word =  recieve \n",
            "suggestions =  ['receive', 'relieve']\n",
            "word 0: receive, probability 0.000131\n",
            "word 1: relieve, probability 0.000019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Q4KP7j1NslB-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}