{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofHADjc6q7dt"
      },
      "source": [
        "# Sequence to Sequence Learning with Neural Networks\n",
        "\n",
        "In this notebook, we'll be building a machine learning model to go from one sequence to another, using PyTorch and torchtext. This will be done on German to English translations, but the method can be applied to any problem that involves going from one sequence to another, such as summarization, i.e. going from a sequence to a shorter sequence in the same language.\n",
        "\n",
        "In this notebook, weimplement the model from the [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215) paper. \n",
        "\n",
        "## Introduction\n",
        "\n",
        "The most common sequence-to-sequence (seq2seq) models are *encoder-decoder* models, which commonly use a *recurrent neural network* (RNN) to *encode* the source (input) sentence into a single vector. In this notebook, we'll refer to this single vector as a *context vector*. We can think of the context vector as being an abstract representation of the entire input sentence. This vector is then *decoded* by a second RNN which learns to output the target (output) sentence by generating it one word at a time.\n",
        "\n",
        "![seq2seq1.png](data:image/png;base64,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)\n",
        "\n",
        "The above image shows an example translation. The input/source sentence, \"guten morgen\", is passed through the embedding layer (yellow) and then input into the encoder (green). We also append a *start of sequence* (`<sos>`) and *end of sequence* (`<eos>`) token to the start and end of sentence, respectively. At each time-step, the input to the encoder RNN is both the embedding, $e$, of the current word, $e(x_t)$, as well as the hidden state from the previous time-step, $h_{t-1}$, and the encoder RNN outputs a new hidden state $h_t$. We can think of the hidden state as a vector representation of the sentence so far. The RNN can be represented as a function of both of $e(x_t)$ and $h_{t-1}$:\n",
        "\n",
        "$$h_t = \\text{EncoderRNN}(e(x_t), h_{t-1})$$\n",
        "\n",
        "We're using the term RNN generally here, it could be any recurrent architecture, such as an *LSTM* (Long Short-Term Memory) or a *GRU* (Gated Recurrent Unit). \n",
        "\n",
        "Here, we have $X = \\{x_1, x_2, ..., x_T\\}$, where $x_1 = \\text{<sos>}, x_2 = \\text{guten}$, etc. The initial hidden state, $h_0$, is usually either initialized to zeros or a learned parameter.\n",
        "\n",
        "Once the final word, $x_T$, has been passed into the RNN via the embedding layer, we use the final hidden state, $h_T$, as the context vector, i.e. $h_T = z$. This is a vector representation of the entire source sentence.\n",
        "\n",
        "Now we have our context vector, $z$, we can start decoding it to get the output/target sentence, \"good morning\". Again, we append start and end of sequence tokens to the target sentence. At each time-step, the input to the decoder RNN (blue) is the embedding, $d$, of current word, $d(y_t)$, as well as the hidden state from the previous time-step, $s_{t-1}$, where the initial decoder hidden state, $s_0$, is the context vector, $s_0 = z = h_T$, i.e. the initial decoder hidden state is the final encoder hidden state. Thus, similar to the encoder, we can represent the decoder as:\n",
        "\n",
        "$$s_t = \\text{DecoderRNN}(d(y_t), s_{t-1})$$\n",
        "\n",
        "Although the input/source embedding layer, $e$, and the output/target embedding layer, $d$, are both shown in yellow in the diagram they are two different embedding layers with their own parameters.\n",
        "\n",
        "In the decoder, we need to go from the hidden state to an actual word, therefore at each time-step we use $s_t$ to predict (by passing it through a `Linear` layer, shown in purple) what we think is the next word in the sequence, $\\hat{y}_t$. \n",
        "\n",
        "$$\\hat{y}_t = f(s_t)$$\n",
        "\n",
        "The words in the decoder are always generated one after another, with one per time-step. We always use `<sos>` for the first input to the decoder, $y_1$, but for subsequent inputs, $y_{t>1}$, we will sometimes use the actual, ground truth next word in the sequence, $y_t$ and sometimes use the word predicted by our decoder, $\\hat{y}_{t-1}$. This is called *teacher forcing*. \n",
        "\n",
        "When training/testing our model, we always know how many words are in our target sentence, so we stop generating words once we hit that many. During inference it is common to keep generating words until the model outputs an `<eos>` token or after a certain amount of words have been generated.\n",
        "\n",
        "Once we have our predicted target sentence, $\\hat{Y} = \\{ \\hat{y}_1, \\hat{y}_2, ..., \\hat{y}_T \\}$, we compare it against our actual target sentence, $Y = \\{ y_1, y_2, ..., y_T \\}$, to calculate our loss. We then use this loss to update all of the parameters in our model.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Torchtext==0.9\n",
        "#torchtext.legacy is not supported on the defult version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19KQKfDRs-GU",
        "outputId": "4fb4d741-a1a8-4f30-9b67-5c64fa6881e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Torchtext==0.9 in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from Torchtext==0.9) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from Torchtext==0.9) (1.21.6)\n",
            "Requirement already satisfied: torch==1.8.0 in /usr/local/lib/python3.7/dist-packages (from Torchtext==0.9) (1.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from Torchtext==0.9) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->Torchtext==0.9) (4.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->Torchtext==0.9) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->Torchtext==0.9) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->Torchtext==0.9) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->Torchtext==0.9) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZodHX8LUq7dy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy.data import Field, BucketIterator\n",
        "import numpy as np\n",
        "import spacy\n",
        "import random\n",
        "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
        "from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grv0dNu_q7d0"
      },
      "source": [
        "Next, we'll create the tokenizers. A tokenizer is used to turn a string containing a sentence into a list of individual tokens that make up that string, e.g. \"good morning!\" becomes [\"good\", \"morning\", \"!\"]. We'll start talking about the sentences being a sequence of tokens from now, instead of saying they're a sequence of words. What's the difference? Well, \"good\" and \"morning\" are both words and tokens, but \"!\" is a token, not a word. \n",
        "\n",
        "spaCy has model for each language (\"de_core_news_sm\" for German and \"en_core_web_sm\" for English) which need to be loaded so we can access the tokenizer of each model. \n",
        "\n",
        "**Note**: the models must first be downloaded using the following on the command line: \n",
        "```\n",
        "python -m spacy download en_core_web_sm\n",
        "python -m spacy download de_core_news_sm\n",
        "```\n",
        "\n",
        "We load the models as such:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_sm\")\n",
        "spacy.cli.download(\"de_core_news_sm\")\n",
        "\n",
        "\n",
        "spacy_ger = spacy.load('de_core_news_sm')\n",
        "spacy_eng = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQ8HcWjYuqCc",
        "outputId": "fd14cb82-364d-4237-f5d2-1b7af7654d3f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5B3adiXq7d0"
      },
      "source": [
        "Next, we create the tokenizer functions. These can be passed to torchtext and will take in the sentence as a string and return the sentence as a list of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fYOYMh2lq7d1"
      },
      "outputs": [],
      "source": [
        "def tokenize_ger(text):\n",
        "    return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
        "\n",
        "\n",
        "def tokenize_eng(text):\n",
        "    return [tok.text for tok in spacy_eng.tokenizer(text)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm0avmvHq7d1"
      },
      "source": [
        "torchtext's `Field`s handle how data should be processed.  \n",
        "\n",
        "We set the `tokenize` argument to the correct tokenization function for each, with German being the source field and English being the target field. The field also appends the \"start of sequence\" and \"end of sequence\" tokens via the `init_token` and `eos_token` arguments, and converts all words to lowercase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1iyEs1wcq7d1"
      },
      "outputs": [],
      "source": [
        "german = Field(tokenize=tokenize_ger, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "\n",
        "english = Field(\n",
        "    tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGs7_2Jdq7d2"
      },
      "source": [
        "Next, we download and load the train, validation and test data. \n",
        "\n",
        "The dataset we'll be using is the [Multi30k dataset](https://github.com/multi30k/dataset). This is a dataset with ~30,000 parallel English, German and French sentences, each with ~12 words per sentence. \n",
        "\n",
        "`exts` specifies which languages to use as the source and target (source goes first) and `fields` specifies which field to use for the source and target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lwJotsZTq7d3"
      },
      "outputs": [],
      "source": [
        "train_data, valid_data, test_data = Multi30k.splits(\n",
        "    exts=(\".de\", \".en\"), fields=(german, english)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn8oPrQQq7d3"
      },
      "source": [
        "We can double check that we've loaded the right number of examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcbakzdJq7d3",
        "outputId": "beac8702-6146-4c11-8c32-d7f075da37ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 29000\n",
            "Number of validation examples: 1014\n",
            "Number of testing examples: 1000\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
        "print(f\"Number of testing examples: {len(test_data.examples)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kEuykIAq7d4"
      },
      "source": [
        "Next, we'll build the *vocabulary* for the source and target languages. The vocabulary is used to associate each unique token with an index (an integer). The vocabularies of the source and target languages are distinct.\n",
        "\n",
        "Using the `min_freq` argument, we only allow tokens that appear at least 2 times to appear in our vocabulary. Tokens that appear only once are converted into an `<unk>` (unknown) token.\n",
        "\n",
        "It is important to note that our vocabulary should only be built from the training set and not the validation/test set. This prevents \"information leakage\" into our model, giving us artifically inflated validation/test scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dGub6PN6q7d4"
      },
      "outputs": [],
      "source": [
        "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "english.build_vocab(train_data, max_size=10000, min_freq=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dQ49xn8q7d5"
      },
      "source": [
        "The final step of preparing the data is to create the iterators.\n",
        "\n",
        "We also need to define a `torch.device`. This is used to tell torchText to put the tensors on the GPU or not. We use the `torch.cuda.is_available()` function, which will return `True` if a GPU is detected on our computer. We pass this `device` to the iterator.\n",
        "\n",
        "When we get a batch of examples using an iterator we need to make sure that all of the source sentences are padded to the same length, the same with the target sentences. Luckily, torchText iterators handle this for us! \n",
        "\n",
        "We use a `BucketIterator` instead of the standard `Iterator` as it creates batches in such a way that it minimizes the amount of padding in both the source and target sentences. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JZIeYTz-q7d5"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AamFUWbdq7d6"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=batch_size,\n",
        "    sort_within_batch=True,\n",
        "    sort_key=lambda x: len(x.src),\n",
        "    device=device,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q31GPjWQq7d8"
      },
      "source": [
        "## Building the Seq2Seq Model\n",
        "\n",
        "We'll be building our model in three parts. The encoder, the decoder and a seq2seq model that encapsulates the encoder and decoder and will provide a way to interface with each.\n",
        "\n",
        "### Encoder\n",
        "\n",
        "First, the encoder, a 2 layer LSTM. The paper we are implementing uses a 4-layer LSTM, but in the interest of training time we cut this down to 2-layers. The concept of multi-layer RNNs is easy to expand from 2 to 4 layers. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KMIIvN7xq7d8"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (seq_length, N) where N is batch size\n",
        "\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "        # embedding shape: (seq_length, N, embedding_size)\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(embedding)\n",
        "        # outputs shape: (seq_length, N, hidden_size)\n",
        "\n",
        "        return hidden, cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usEq0m15q7d9"
      },
      "source": [
        "### Decoder\n",
        "\n",
        "Next, we'll build our decoder, which will also be a 2-layer (4 in the paper) LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "58gq0lqZq7d9"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
        "    ):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "        # x shape: (N) where N is for batch size, we want it to be (1, N), seq_length\n",
        "        # is 1 here because we are sending in a single word and not a sentence\n",
        "        x = x.unsqueeze(0)\n",
        "\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "        # embedding shape: (1, N, embedding_size)\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
        "        # outputs shape: (1, N, hidden_size)\n",
        "\n",
        "        predictions = self.fc(outputs)\n",
        "\n",
        "        # predictions shape: (1, N, length_target_vocabulary) to send it to\n",
        "        # loss function we want it to be (N, length_target_vocabulary) so we're\n",
        "        # just gonna remove the first dim\n",
        "        predictions = predictions.squeeze(0)\n",
        "\n",
        "        return predictions, hidden, cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOX2VmU1q7d9"
      },
      "source": [
        "### Seq2Seq\n",
        "\n",
        "For the final part of the implemenetation, we'll implement the seq2seq model. This will handle: \n",
        "- receiving the input/source sentence\n",
        "- using the encoder to produce the context vectors \n",
        "- using the decoder to produce the predicted output/target sentence\n",
        "\n",
        "\n",
        "The `Seq2Seq` model takes in an `Encoder`, `Decoder`, and a `device` (used to place tensors on the GPU, if it exists)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1zmkEwNuq7d9"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
        "        batch_size = source.shape[1]\n",
        "        target_len = target.shape[0]\n",
        "        target_vocab_size = len(english.vocab)\n",
        "\n",
        "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "\n",
        "        hidden, cell = self.encoder(source)\n",
        "\n",
        "        # Grab the first input to the Decoder which will be <SOS> token\n",
        "        x = target[0]\n",
        "\n",
        "        for t in range(1, target_len):\n",
        "            # Use previous hidden, cell as context from encoder at start\n",
        "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
        "\n",
        "            # Store next output prediction\n",
        "            outputs[t] = output\n",
        "\n",
        "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
        "            best_guess = output.argmax(1)\n",
        "\n",
        "            # With probability of teacher_force_ratio we take the actual next word\n",
        "            # otherwise we take the word that the Decoder predicted it to be.\n",
        "            # Teacher Forcing is used so that the model gets used to seeing\n",
        "            # similar inputs at training and testing time, if teacher forcing is 1\n",
        "            # then inputs at test time might be completely different than what the\n",
        "            # network is used to. This was a long comment.\n",
        "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ5sazw-q7d-"
      },
      "source": [
        "# Training the Seq2Seq Model\n",
        "\n",
        "Now we have our model implemented, we can begin training it. \n",
        "\n",
        "First, we'll initialize our model. As mentioned before, the input and output dimensions are defined by the size of the vocabulary. The embedding dimesions and dropout for the encoder and decoder can be different, but the number of layers and the size of the hidden/cell states must be the same. \n",
        "\n",
        "We then define the encoder, decoder and then our Seq2Seq model, which we place on the `device`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9SaHvQIq7d-"
      },
      "outputs": [],
      "source": [
        "# Training hyperparameters\n",
        "num_epochs = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "\n",
        "# Model hyperparameters\n",
        "load_model = False\n",
        "\n",
        "\n",
        "input_size_encoder = len(german.vocab)\n",
        "input_size_decoder = len(english.vocab)\n",
        "output_size = len(english.vocab)\n",
        "encoder_embedding_size = 300\n",
        "decoder_embedding_size = 300\n",
        "hidden_size = 1024  # Needs to be the same for both RNN's\n",
        "num_layers = 2\n",
        "enc_dropout = 0.5\n",
        "dec_dropout = 0.5\n",
        "\n",
        "# Tensorboard to get nice loss plot\n",
        "writer = SummaryWriter(f\"runs/loss_plot\")\n",
        "step = 0\n",
        "\n",
        "\n",
        "\n",
        "encoder_net = Encoder(\n",
        "    input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout\n",
        ").to(device)\n",
        "\n",
        "decoder_net = Decoder(\n",
        "    input_size_decoder,\n",
        "    decoder_embedding_size,\n",
        "    hidden_size,\n",
        "    output_size,\n",
        "    num_layers,\n",
        "    dec_dropout,\n",
        ").to(device)\n",
        "\n",
        "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "\n",
        "if load_model:\n",
        "    load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)\n",
        "\n",
        "\n",
        "sentence = \"ein boot mit mehreren männern darauf wird von einem großen pferdegespann ans ufer gezogen.\"\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
        "\n",
        "    checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
        "    save_checkpoint(checkpoint)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    translated_sentence = translate_sentence(\n",
        "        model, sentence, german, english, device, max_length=50\n",
        "    )\n",
        "\n",
        "    print(f\"Translated example sentence: \\n {translated_sentence}\")\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_iterator):\n",
        "        # Get input and targets and get to cuda\n",
        "        inp_data = batch.src.to(device)\n",
        "        target = batch.trg.to(device)\n",
        "\n",
        "        # Forward prop\n",
        "        output = model(inp_data, target)\n",
        "\n",
        "        # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
        "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
        "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
        "        # way that we have output_words * batch_size that we want to send in into\n",
        "        # our cost function, so we need to do some reshapin. While we're at it\n",
        "        # Let's also remove the start token while we're at it\n",
        "        output = output[1:].reshape(-1, output.shape[2])\n",
        "        target = target[1:].reshape(-1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Back prop\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
        "        # within a healthy range\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "        # Gradient descent step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Plot to tensorboard\n",
        "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
        "        step += 1\n",
        "\n",
        "\n",
        "score = bleu(test_data[1:100], model, german, english, device)\n",
        "print(f\"Bleu score {score*100:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing our translator:**"
      ],
      "metadata": {
        "id": "egZWQrWMZdLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng_sentence = 'A man with a blue shirt is running in the street'\n",
        "sentence = 'Ein Mann mit blauem Hemd läuft auf der Straße.'\n",
        "model.eval()\n",
        "\n",
        "translated_sentence = translate_sentence(\n",
        "    model, sentence, german, english, device, max_length=50)\n",
        "\n",
        "print('Correct English translation: \\n {}'.format(eng_sentence))\n",
        "print(f\"Translation by our machine: \\n {translated_sentence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dFm-ARIBck2",
        "outputId": "36f90cd1-1617-49c5-aac2-be9a7ed30d0c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct English translation: \n",
            " A man with a blue shirt is running in the street\n",
            "Translation by our machine: \n",
            " ['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'running', 'on', 'the', 'street', '.', '<eos>']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "1 - Seq2Seq LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}